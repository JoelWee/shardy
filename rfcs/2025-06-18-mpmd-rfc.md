# MPMD RFC

## Motivation – why MPMD instead of SPMD?

As models get larger and resources become more constrained, the flexibility and
performance that MPMD provides is increasingly beneficial.

With MPMD (“multiple-program multiple-data”), users can express more complex
programs than SPMD (“single-program multiple-data”).

We focus on two main motivating cases:

1.  Pipeline parallelism, and
2.  Heterogeneous compute clusters.

### Quick recap on pipeline parallelism

Recall that pipeline parallelism is one of many parallelism strategies
([link](https://jax-ml.github.io/scaling-book/training/#tensor-parallelism))
that helps fit large models over many devices. Pipeline parallelism basically
means chopping a model into smaller components, e.g. as follows:

![Figure1](images/2025-06-17-mpmd-rfc/pipelined_transformer.jpg)

Pipeline parallelism is easily composed with other tensor parallelism
strategies: e.g. within each pipeline stage, we can have data parallelism,
megatron sharding, etc.

The key benefit of pipeline parallelism over tensor parallelism is that the
amount of data communicated scales not with parameters, but with the activation
sizes. And this is particularly important for some low-latency uses and also for
parallelism across slow networks (e.g. multi-host GPU setups, or across DCN for
TPUs).

### MPMD and pipeline parallelism

The relevance of MPMD is that the way we’ve chopped up our program above is an
MPMD program: notice that the programs on mesh 1 and 4 differ from those on mesh
2 and 3.

Some pipeline schedules are doable in SPMD (e.g. GPIPE), but implementation is
often tricky and invasive. Furthermore, many pipeline schedules are MPMD
parallel programs by nature: different programs may be executed on different
stages at a given point, e.g. 1F1B or Near Zero Bubble.

**Shardy:MPMD aims to make pipelining a program easy and intuitive**.

### Heterogeneous compute clusters

Beyond pipeline parallelism, MPMD also allows us to execute a program over
different device types. Note that this isn’t possible in the SPMD paradigm, as
the compiled programs are necessarily different over different device types.

The growing demand for hardware means that heterogeneous compute clusters are
sometimes the most economical way of achieving the necessary compute.
Furthermore, there are potential efficiency gains from mixing hardware with
different performance profiles.

### When to use Shardy:MPMD

Because Shardy:MPMD (and MPMD in general) involves longer compile times and
additional MPMD-specific complexity/knowledge, it is often good to start with an
SPMD program, and then migrate to MPMD when it is needed.

As mentioned above, it is particularly useful when pipeline parallelism or
heterogeneous compute is needed. These situations often arise for:

*   Large training workloads
*   Running on cheaper hardware or hardware with slow network connection.
*   Utilizing the maximum amount of hardware, regardless of device type.

## Overview

### What is Shardy:MPMD?

Shardy:MPMD is an MLIR library designed for intuitive and performant MPMD
partitioning whilst retaining single-device programming semantics, and is
composable with SPMD partitioning. To achieve this, the MPMD partitioning is
done via annotations and compiler passes (like Shardy) and doesn’t require
manual management.

The **Shardy:MPMD program is** **just a bunch of SPMD programs** with the
orchestration and data transfer between the SPMD programs statically specified.
This allows us to keep the SPMD-program semantics, and hence allows moving from
SPMD to MPMD with minimal changes. Because we do this in MLIR, it is independent
of any runtime. E.g. we have developed this using IFRT IR + Pathways, but it can
be lowered to another IR.

To go from an SPMD program to an MPMD program with Shardy:MPMD, the user only
needs to annotate parts of their program with names and provide a name-to-mesh
assignment map. Shardy:MPMD will then handle the MPMD and SPMD sharding
propagation, and any scheduling (e.g. pipeline schedules) as provided by the
user.

![Figure2](images/2025-06-17-mpmd-rfc/mpmd_intro.jpg)

### MPMD + JAX

While Shardy:MPMD doesn’t rely on any specific ML framework, we have developed
it with an experimental JAX API.

With this API, moving from SPMD to MPMD is simple: add some named_computation
ops, and use `mpmd.jit` instead of `jax.jit`.

```
def simple_train_step(x):
  c1 = mpmd.named_computation(lambda y: y + y, name="c1")(x)
  c2 = mpmd.named_computation(lambda y: y + y, name="c2")(c0)
  return c2

mpmd_config = mpmd.make_config(
  topology = {
    "m1": jax.sharding.Mesh(mesh1_devices, axes),
    "m2": jax.sharding.Mesh(mesh2_devices, axes),
  },
  assignment = { "c1": "m1", "c2": "m2" }
)

samples = jnp.ones((512,512))
lowered = mpmd.jit(simple_train_step, mpmd_config).lower(samples)
c = lowered.compile()

placed_samples = jax.device_put(
samples,
lowered.function_named_shardings.inputs[0]
)
res = c(placed_samples)
```

To execute the MPMD program, we currently require Pathways on Cloud
([link](https://cloud.google.com/ai-hypercomputer/docs/workloads/pathways-on-cloud/pathways-intro)).
We lower to IFRT IR (an open source runtime IR,
[link](https://github.com/openxla/xla/tree/main/xla/python/ifrt/ir)) which
Pathways executes, so we can replace it with any runtime that handles IFRT IR or
lower from IFRT IR to another IR.

### Components

The MPMD program is represented as a sequence of SPMD computation units
(“fragments”) and data transfers (“transfers”) between them, with fragments
assigned to groups of devices (SPMD “meshes”).

To decouple changes in MPMD partitioning from changes to the model, we allow our
input program to be given labels, instead of assigning the meshes explicitly.

Furthermore, for ease-of-use, we allow partial labelling/assignment. I.e. not
every computation/array needs to be labelled.

To obtain a performant MPMD program, we have a series of transformations as
follows:

*   **Mesh assignment**: Assigns computations with labels to their meshes, as
    provided by the user, and creates transfers between these computations.
*   **Mesh inference**: Takes a partially assigned MPMD program (i.e. not every
    op has been assigned a mesh), and completes the assignment. I.e. assigns all
    meshless ops to a fragment on some mesh, while minimizing transfers.
*   **Fragment scheduling**: Applies a user-provided schedule to the MPMD
    program. E.g. a pipeline schedule like 1F1B, or Near Zero Bubble.
*   **Fragment merging**: Merges fragments together according to user input.
    This allows for finer-grained labelling of programs which allows for more
    flexibility in assignment, e.g. labelling a transformer by its layers
    instead of pipeline stages. It also allows for further optimizations, e.g.
    merging the forward and backward of the last pipeline stage in 1F1B.
*   **SPMD Sharding propagation**: Applies sharding propagation to the entire
    MPMD program using Shardy.
*   **Export**: A mix of passes which prepares the MLIR module for compilation
    (XLA or otherwise). E.g. dedupes similar programs together, etc.

## Examples

To give a flavour of what these components do, we have two examples below:

1.  A simple example demonstrating mesh assignment and inference.
2.  An example demonstrating a 1F1B pipeline schedule

### Simple example of mesh inference

Here we just have a simple program with two “addition layers” , and some
operations outside the named_computations (“nameless ops”).

We map layer1 to m1 and layer2 to m2, and note that the transfers are inserted
between the meshes.

Then mesh inference will push the multiply and divide into the corresponding
fragments.

#### Initial

```
#topology = #sdy.topology<<"m1": <"x"=2>>, <"m2": <"x"=2>>>
!t = tensor<4xf32>

func.func @main(%arg0: !t, %arg1: !t) -> (!t, !t)
  attributes {topology=#topology} {
  %1 = mpmd.named_computation<"layer1"> (%arg0, %arg1) (%arg2: !t, %arg3: !t) {
    %10 = stablehlo.add %arg2, %arg2 : !t
    mpmd.return %10 : !t
  } : (!t, !t) -> !t

  %c = stablehlo.constant dense<0.000000e+00> : !t
  %2 = mpmd.named_computation<"layer2"> (%1, %c) (%arg2: !t, %arg3: !t) {
    %10 = stablehlo.add %arg2, %arg2 : !t
    mpmd.return %10 : !t
  } : (!t, !t) -> !t

  %3 = stablehlo.multiply %1, %1 : !t
  %4 = stablehlo.divide %2, %2 : !t

  func.return %3, %4  : !t, !t
}
```

#### Mesh assignment

```
!m1_t = !mpmd.mesh_tensor<"m1", !t>
!m2_t = !mpmd.mesh_tensor<"m2", !t>

// Map layer1 -> m1, layer2 -> m2
module {
  sdy.mesh @mesh = <["x"=2]>
  func.func @main(%arg0: !t, %arg1: !t) -> (!t, !t) attributes {topology=#topology} {
    %0 = mpmd.assign %arg0 : (!t) -> !m1_t
    %1 = mpmd.fragment<mesh="m1", origin=["layer1"], stage=1> (%0) (%arg2: !t) {
      %8 = stablehlo.add %arg2, %arg2 : !t
      mpmd.return %8 : !t
    } : (!m1_t) -> !m1_t
    %2 = mpmd.unassign %1 : (!m1_t) -> !t
    %3 = mpmd.transfer %1 : (!m1_t) -> !m2_t
    %4 = mpmd.fragment<mesh="m2", origin=["layer2"], stage=2> (%3) (%arg2: !t) {
      %8 = stablehlo.add %arg2, %arg2 : !t
      mpmd.return %8 : !t
    } : (!m2_t) -> !m2_t
    %5 = mpmd.unassign %4 : (!m2_t) -> !t
    %6 = stablehlo.multiply %2, %2 : !t
    %7 = stablehlo.divide %5, %5 : !t
    return %6, %7 : !t, !t
  }
}

```

#### Mesh inference

```
module {
  sdy.mesh @mesh = <["x"=2]>
  func.func @main(%arg0: !m1_t, %arg1: !m1_t) -> (!m1_t, !m2_t) attributes {topology=#topology} {
    %0:2 = mpmd.fragment<mesh="m1", origin=["layer1"], stage=1> (%arg0) (%arg2: tensor<4xf32>) {
      %3 = stablehlo.add %arg2, %arg2 : tensor<4xf32>
      %4 = stablehlo.multiply %3, %3 : tensor<4xf32>
      mpmd.return %3, %4 : tensor<4xf32>, tensor<4xf32>
    } : (!m1_t) -> (!m1_t, !m1_t)
    %1 = mpmd.transfer %0#0 : (!m1_t) -> !m2_t
    %2 = mpmd.fragment<mesh="m2", origin=["layer2"], stage=2> (%1) (%arg2: tensor<4xf32>) {
      %3 = stablehlo.add %arg2, %arg2 : tensor<4xf32>
      %4 = stablehlo.divide %3, %3 : tensor<4xf32>
      mpmd.return %4 : tensor<4xf32>
    } : (!m2_t) -> !m2_t
    return %0#1, %2 : !m1_t, !m2_t
  }
}
```

### Scheduling + merging + export for a 2 microbatch, 2 stage pipeline

Here we just have a slightly more complicated program with:

*   Two forward layers (“layer1”, “layer2”) and two backward layers
    (“layer1”(1), “layer2”(1))
    *   Note that the number in parenthesis denotes the derivative count. E.g.
        “layer2”(n) would be the n-th derivative of “layer2”.
*   Two microbatches (call_counter 0 and 1 – we’ll refer to these as “mb”)
*   The input is batch sharded.

We then apply as follows:

1.  **1F1B pipeline scheduling**: Note that the layer1 at mb=1 now comes before
    layer1(1) at mb=0
2.  **Merging**: layer2 and layer2(1) are merged together in each mb
3.  **Sharding propagation**: the entire program is now batch-sharded.
4.  **Export**: Functions across the microbatches are now deduped
5.  **Lower to IFRT IR**: The program is represented in IFRT IR.

Where the pipeline scheduling and merging are user-controlled. E.g. the user
could pass another pipeline schedule other than 1F1B (DualPipe or GPIPE etc.).
See “Detailed Design” below for more details.

#### Initial

```

#topology = #sdy.topology<<"m1": <"x"=2>>, <"m2": <"x"=2>>>
#batch_shard = #sdy.sharding<@mesh, [{"x"}]>

!t = tensor<4xf32>
!m1_t = !mpmd.mesh_tensor<"m1", !t>
!m2_t = !mpmd.mesh_tensor<"m2", !t>

module attributes {mpmd.fragments.global_view} {
  sdy.mesh @mesh = <["x"=2]>
  func.func @main(%arg0: !m1_t {sdy.sharding=#batch_shard}) -> (!m1_t, !m1_t) attributes {topology=#topology} {
    %0 = mpmd.fragment<mesh="m1", origin=["layer1"], stage=1> (%arg0) {call_counter = 0 : ui32} (%arg2: !t) {
      %30 = stablehlo.add %arg2, %arg2 : !t
      mpmd.return %30 : !t
    } : (!m1_t) -> !m1_t

    %1 = mpmd.transfer %0 : (!m1_t) -> !m2_t

    %2 = mpmd.fragment<mesh="m2", origin=["layer2"], stage=2> (%1) {call_counter = 0 : ui32} (%arg2: !t) {
      %30 = stablehlo.add %arg2, %arg2 : !t
      mpmd.return %30 : !t
    } : (!m2_t) -> !m2_t


    %3 = mpmd.fragment<mesh="m2", origin=["layer2"(1)], stage=2> (%2) {call_counter = 0 : ui32} (%arg2: !t) {
      %30 = stablehlo.add %arg2, %arg2 : !t
      mpmd.return %30 : !t
    } : (!m2_t) -> !m2_t

    %4 = mpmd.transfer %3 : (!m2_t) -> !m1_t

    %5 = mpmd.fragment<mesh="m1", origin=["layer1"(1)], stage=1> (%4) {call_counter = 0 : ui32} (%arg2: !t) {
      %30 = stablehlo.add %arg2, %arg2 : !t
      mpmd.return %30 : !t
    } : (!m1_t) -> !m1_t


    %10 = mpmd.fragment<mesh="m1", origin=["layer1"], stage=1> (%arg0) {call_counter = 1 : ui32} (%arg2: !t) {
      %30 = stablehlo.add %arg2, %arg2 : !t
      mpmd.return %30 : !t
    } : (!m1_t) -> !m1_t

    %11 = mpmd.transfer %10 : (!m1_t) -> !m2_t

    %12 = mpmd.fragment<mesh="m2", origin=["layer2"], stage=2> (%11) {call_counter = 1 : ui32} (%arg2: !t) {
      %30 = stablehlo.add %arg2, %arg2 : !t
      mpmd.return %30 : !t
    } : (!m2_t) -> !m2_t


    %13 = mpmd.fragment<mesh="m2", origin=["layer2"(1)], stage=2> (%12) {call_counter = 1 : ui32} (%arg2: !t) {
      %30 = stablehlo.add %arg2, %arg2 : !t
      mpmd.return %30 : !t
    } : (!m2_t) -> !m2_t

    %14 = mpmd.transfer %13 : (!m2_t) -> !m1_t

    %15 = mpmd.fragment<mesh="m1", origin=["layer1"(1)], stage=1> (%14) {call_counter = 1 : ui32} (%arg2: !t) {
      %30 = stablehlo.add %arg2, %arg2 : !t
      mpmd.return %30 : !t
    } : (!m1_t) -> !m1_t

    return %5, %15 : !m1_t, !m1_t
  }
}
```

#### After scheduling

```


func.func @main(%arg0: !m1_t {sdy.sharding = #batch_shard}) -> (!m1_t, !m1_t) attributes {topology = #topology} {

  %0 = mpmd.fragment<mesh="m1", origin=["layer1"], stage=1> (%arg0) {call_counter = 0 : ui32} (%arg1: !t) {
    %12 = stablehlo.add %arg1, %arg1 : !t
    mpmd.return %12 : !t
  } : (!m1_t) -> !m1_t
  %1 = mpmd.transfer %0 : (!m1_t) -> !m2_t

  %2 = mpmd.fragment<mesh="m2", origin=["layer2"], stage=2> (%1) {call_counter = 0 : ui32} (%arg1: !t) {
    %12 = stablehlo.add %arg1, %arg1 : !t
    mpmd.return %12 : !t
  } : (!m2_t) -> !m2_t
  %3 = mpmd.fragment<mesh="m2", origin=["layer2"(1)], stage=2> (%2) {call_counter = 0 : ui32} (%arg1: !t) {
    %12 = stablehlo.add %arg1, %arg1 : !t
    mpmd.return %12 : !t
  } : (!m2_t) -> !m2_t
  %4 = mpmd.transfer %3 : (!m2_t) -> !m1_t

  %5 = mpmd.fragment<mesh="m1", origin=["layer1"], stage=1> (%arg0) {call_counter = 1 : ui32} (%arg1: !t) {
    %12 = stablehlo.add %arg1, %arg1 : !t
    mpmd.return %12 : !t
  } : (!m1_t) -> !m1_t
  %6 = mpmd.transfer %5 : (!m1_t) -> !m2_t
  %7 = mpmd.fragment<mesh="m2", origin=["layer2"], stage=2> (%6) {call_counter = 1 : ui32} (%arg1: !t) {
    %12 = stablehlo.add %arg1, %arg1 : !t
    mpmd.return %12 : !t
  } : (!m2_t) -> !m2_t
  %8 = mpmd.fragment<mesh="m2", origin=["layer2"(1)], stage=2> (%7) {call_counter = 1 : ui32} (%arg1: !t) {
    %12 = stablehlo.add %arg1, %arg1 : !t
    mpmd.return %12 : !t
  } : (!m2_t) -> !m2_t
  %9 = mpmd.transfer %8 : (!m2_t) -> !m1_t

  %10 = mpmd.fragment<mesh="m1", origin=["layer1"(1)], stage=1> (%4) {call_counter = 0 : ui32} (%arg1: !t) {
    %12 = stablehlo.add %arg1, %arg1 : !t
    mpmd.return %12 : !t
  } : (!m1_t) -> !m1_t
  %11 = mpmd.fragment<mesh="m1", origin=["layer1"(1)], stage=1> (%9) {call_counter = 1 : ui32} (%arg1: !t) {
    %12 = stablehlo.add %arg1, %arg1 : !t
    mpmd.return %12 : !t
  } : (!m1_t) -> !m1_t

  return %10, %11 : !m1_t, !m1_t
}
```

#### After merging

```
module attributes {mpmd.fragments.global_view} {
  sdy.mesh @mesh = <["x"=2]>
  func.func @main(%arg0: !m1_t {sdy.sharding = #batch_shard}) -> (!m1_t, !m1_t) attributes {topology = #topology} {

    %0 = mpmd.fragment<mesh="m1", origin=["layer1"], stage=1> (%arg0) {call_counter = 0 : ui32} (%arg1: !t) {
      %10 = stablehlo.add %arg1, %arg1 : !t
      mpmd.return %10 : !t
    } : (!m1_t) -> !m1_t
    %1 = mpmd.transfer %0 : (!m1_t) -> !m2_t
    %2 = mpmd.fragment<mesh="m2", origin=["layer2", "layer2"(1)], stage=2> (%1) {call_counter = 0 : ui32} (%arg1: !t) {
      %10 = stablehlo.add %arg1, %arg1 : !t
      %11 = stablehlo.add %10, %10 : !t
      mpmd.return %11 : !t
    } : (!m2_t) -> !m2_t
    %3 = mpmd.transfer %2 : (!m2_t) -> !m1_t

    %4 = mpmd.fragment<mesh="m1", origin=["layer1"], stage=1> (%arg0) {call_counter = 1 : ui32} (%arg1: !t) {
      %10 = stablehlo.add %arg1, %arg1 : !t
      mpmd.return %10 : !t
    } : (!m1_t) -> !m1_t
    %5 = mpmd.transfer %4 : (!m1_t) -> !m2_t
    %6 = mpmd.fragment<mesh="m2", origin=["layer2", "layer2"(1)], stage=2> (%5) {call_counter = 1 : ui32} (%arg1: !t) {
      %10 = stablehlo.add %arg1, %arg1 : !t
      %11 = stablehlo.add %10, %10 : !t
      mpmd.return %11 : !t
    } : (!m2_t) -> !m2_t
    %7 = mpmd.transfer %6 : (!m2_t) -> !m1_t

    %8 = mpmd.fragment<mesh="m1", origin=["layer1"(1)], stage=1> (%3) {call_counter = 0 : ui32} (%arg1: !t) {
      %10 = stablehlo.add %arg1, %arg1 : !t
      mpmd.return %10 : !t
    } : (!m1_t) -> !m1_t
    %9 = mpmd.fragment<mesh="m1", origin=["layer1"(1)], stage=1> (%7) {call_counter = 1 : ui32} (%arg1: !t) {
      %10 = stablehlo.add %arg1, %arg1 : !t
      mpmd.return %10 : !t
    } : (!m1_t) -> !m1_t

    return %8, %9 : !m1_t, !m1_t
  }
}
```

#### After sharding propagation

```
!m1_t_batch = !mpmd.mesh_tensor<"m1", !t, sharding=<@mesh, [{"x"}]>>
!m2_t_batch = !mpmd.mesh_tensor<"m2", !t, sharding=<@mesh, [{"x"}]>>

module attributes {mpmd.fragments.global_view} {
  sdy.mesh @mesh = <["x"=2]>
  func.func @main(%arg0: !m1_t_batch) -> (!m1_t_batch, !m1_t_batch) attributes {topology = #topology} {
    %0 = mpmd.fragment<mesh="m1", origin=["layer1"], stage=1> (%arg0) {call_counter = 0 : ui32} (%arg1: !t) {
      %10 = stablehlo.add %arg1, %arg1 : !t
      mpmd.return %10 : !t
    } : (!m1_t_batch) -> !m1_t_batch
    %1 = mpmd.transfer %0 : (!m1_t_batch) -> !m2_t_batch
    %2 = mpmd.fragment<mesh="m2", origin=["layer2", "layer2"(1)], stage=2> (%1) {call_counter = 0 : ui32} (%arg1: !t) {
      %10 = stablehlo.add %arg1, %arg1 : !t
      %11 = stablehlo.add %10, %10 : !t
      mpmd.return %11 : !t
    } : (!m2_t_batch) -> !m2_t_batch
    %3 = mpmd.transfer %2 : (!m2_t_batch) -> !m1_t_batch

    %4 = mpmd.fragment<mesh="m1", origin=["layer1"], stage=1> (%arg0) {call_counter = 1 : ui32} (%arg1: !t) {
      %10 = stablehlo.add %arg1, %arg1 : !t
      mpmd.return %10 : !t
    } : (!m1_t_batch) -> !m1_t_batch
    %5 = mpmd.transfer %4 : (!m1_t_batch) -> !m2_t_batch
    %6 = mpmd.fragment<mesh="m2", origin=["layer2", "layer2"(1)], stage=2> (%5) {call_counter = 1 : ui32} (%arg1: !t) {
      %10 = stablehlo.add %arg1, %arg1 : !t
      %11 = stablehlo.add %10, %10 : !t
      mpmd.return %11 : !t
    } : (!m2_t_batch) -> !m2_t_batch
    %7 = mpmd.transfer %6 : (!m2_t_batch) -> !m1_t_batch

    %8 = mpmd.fragment<mesh="m1", origin=["layer1"(1)], stage=1> (%3) {call_counter = 0 : ui32} (%arg1: !t) {
      %10 = stablehlo.add %arg1, %arg1 : !t
      mpmd.return %10 : !t
    } : (!m1_t_batch) -> !m1_t_batch
    %9 = mpmd.fragment<mesh="m1", origin=["layer1"(1)], stage=1> (%7) {call_counter = 1 : ui32} (%arg1: !t) {
      %10 = stablehlo.add %arg1, %arg1 : !t
      mpmd.return %10 : !t
    } : (!m1_t_batch) -> !m1_t_batch

    return %8, %9 : !m1_t_batch, !m1_t_batch
  }
}
```

#### Export

```
module attributes {mpmd.fragments.global_view} {
  func.func @main(%arg0: !m1_t_batch) -> (!m1_t_batch, !m1_t_batch) attributes {topology = #topology} {
    %0 = mpmd.fragment_call<mesh="m1", origin=["layer1"]> @p0_stage1_fwd_calls0to1.main(%arg0) : (!m1_t_batch) -> !m1_t_batch
    %1 = mpmd.transfer %0 : (!m1_t_batch) -> !m2_t_batch
    %2 = mpmd.fragment_call<mesh="m2", origin=["layer2", "layer2"(1)]> @p1_stage2_fwd_bwd_calls0to1.main(%1) : (!m2_t_batch) -> !m2_t_batch
    %3 = mpmd.transfer %2 : (!m2_t_batch) -> !m1_t_batch

    %4 = mpmd.fragment_call<mesh="m1", origin=["layer1"]> @p0_stage1_fwd_calls0to1.main(%arg0) : (!m1_t_batch) -> !m1_t_batch
    %5 = mpmd.transfer %4 : (!m1_t_batch) -> !m2_t_batch
    %6 = mpmd.fragment_call<mesh="m2", origin=["layer2", "layer2"(1)]> @p1_stage2_fwd_bwd_calls0to1.main(%5) : (!m2_t_batch) -> !m2_t_batch
    %7 = mpmd.transfer %6 : (!m2_t_batch) -> !m1_t_batch

    %8 = mpmd.fragment_call<mesh="m1", origin=["layer1"(1)]> @p2_stage1_bwd_calls0to1.main(%3) : (!m1_t_batch) -> !m1_t_batch
    %9 = mpmd.fragment_call<mesh="m1", origin=["layer1"(1)]> @p2_stage1_bwd_calls0to1.main(%7) : (!m1_t_batch) -> !m1_t_batch

    return %8, %9 : !m1_t_batch, !m1_t_batch
  }
  func.func @p0_stage1_fwd_calls0to1.main(%arg0: !t) -> !t attributes {mesh_shape = #sdy.mesh<"x"=2>} {
    %0 = stablehlo.add %arg0, %arg0 : !t
    return %0 : !t
  }
  func.func @p1_stage2_fwd_bwd_calls0to1.main(%arg0: !t {tf.aliasing_output = 0 : i32}) -> !t attributes {mesh_shape = #sdy.mesh<"x"=2>} {
    %0 = stablehlo.add %arg0, %arg0 : !t
    %1 = stablehlo.add %0, %0 : !t
    return %1 : !t
  }
  func.func @p2_stage1_bwd_calls0to1.main(%arg0: !t {tf.aliasing_output = 0 : i32}) -> !t attributes {mesh_shape = #sdy.mesh<"x"=2>} {
    %0 = stablehlo.add %arg0, %arg0 : !t
    return %0 : !t
  }
}

// Lowered to IFRT


```

#### Lowered to IFRT

```

!m1_ifrt_array = !ifrt.array<!t, #ifrt.sharding_param<2 to [0] on 2>, [0, 1]>
!m2_ifrt_array = !ifrt.array<!t, #ifrt.sharding_param<2 to [0] on 2>, [2, 3]>

module {
  func.func @main(%arg0: !m1_ifrt_array) -> (!m1_ifrt_array, !m1_ifrt_array) attributes {ifrt.function} {
    %outputs, %control_output = ifrt.Call @p0_stage1_fwd_calls0to1.main::@main(%arg0) on devices [0, 1] {ifrt.mesh_name = "m1"} : (!m1_ifrt_array) -> !m1_ifrt_array
    %outputs_0, %control_output_1 = ifrt.CopyArrays(%outputs) : (!m1_ifrt_array) -> !m2_ifrt_array
    %outputs_2, %control_output_3 = ifrt.Call @p1_stage2_fwd_bwd_calls0to1.main::@main(%outputs_0) on devices [2, 3] {ifrt.mesh_name = "m2", io_aliases = [array<i32: 0, 0>]} : (!m2_ifrt_array) -> !m2_ifrt_array
    %outputs_4, %control_output_5 = ifrt.CopyArrays(%outputs_2) : (!m2_ifrt_array) -> !m1_ifrt_array
    %outputs_6, %control_output_7 = ifrt.Call @p0_stage1_fwd_calls0to1.main::@main(%arg0) after %control_output on devices [0, 1] {ifrt.mesh_name = "m1"} : (!m1_ifrt_array) -> !m1_ifrt_array
    %outputs_8, %control_output_9 = ifrt.CopyArrays(%outputs_6) : (!m1_ifrt_array) -> !m2_ifrt_array
    %outputs_10, %control_output_11 = ifrt.Call @p1_stage2_fwd_bwd_calls0to1.main::@main(%outputs_8) after %control_output_3 on devices [2, 3] {ifrt.mesh_name = "m2", io_aliases = [array<i32: 0, 0>]} : (!m2_ifrt_array) -> !m2_ifrt_array
    %outputs_12, %control_output_13 = ifrt.CopyArrays(%outputs_10) : (!m2_ifrt_array) -> !m1_ifrt_array
    %outputs_14, %control_output_15 = ifrt.Call @p2_stage1_bwd_calls0to1.main::@main(%outputs_4) after %control_output_7 on devices [0, 1] {ifrt.mesh_name = "m1", io_aliases = [array<i32: 0, 0>]} : (!m1_ifrt_array) -> !m1_ifrt_array
    %outputs_16, %control_output_17 = ifrt.Call @p2_stage1_bwd_calls0to1.main::@main(%outputs_12) after %control_output_15 on devices [0, 1] {ifrt.mesh_name = "m1", io_aliases = [array<i32: 0, 0>]} : (!m1_ifrt_array) -> !m1_ifrt_array
    return %outputs_14, %outputs_16 : !m1_ifrt_array, !m1_ifrt_array
  }
  module @p0_stage1_fwd_calls0to1.main attributes {sym_visibility = "private"} {
    func.func @main(%arg0: !t) -> !t {
      %0 = stablehlo.add %arg0, %arg0 : !t
      return %0 : !t
    }
  }
  module @p1_stage2_fwd_bwd_calls0to1.main attributes {sym_visibility = "private"} {
    func.func @main(%arg0: !t {tf.aliasing_output = 0 : i32}) -> !t {
      %0 = stablehlo.add %arg0, %arg0 : !t
      %1 = stablehlo.add %0, %0 : !t
      return %1 : !t
    }
  }
  module @p2_stage1_bwd_calls0to1.main attributes {sym_visibility = "private"} {
    func.func @main(%arg0: !t {tf.aliasing_output = 0 : i32}) -> !t {
      %0 = stablehlo.add %arg0, %arg0 : !t
      return %0 : !t
    }
  }
}

```

## Detailed design

Here, we go into the key ideas of the different MPMD transformations.

### Mesh assignment

<ins>Summary</ins>: Assigns the labelled computations to the meshes, and creates
cross-mesh transfers. Also assigns inputs and outputs to meshes.

The assignment is simple enough. It uses the user-provided mapping of:

*   names to meshes, and
*   Input and output indices to meshes.

Assigning names to meshes is the common approach but assigning inputs and
outputs explicitly can also be very useful, especially for making sure that
params and outputs are at the expected locations. This is similar to the in/out
shardings specifications of JAX’s jit API.

For creating cross-mesh transfers, we restrict this to only direct mesh changes.
E.g. where we have a named user of a named result/value, and the names are
assigned to different meshes.

```
%1 = mpmd.named_computation<"layer1">...
%2 = mpmd.named_computation<"layer2"> (%1) ...

Map layer1 -> mesh1, layer2 -> mesh2
~~>

%1 = mpmd.fragment<"m1">...
%t = mpmd.transfer %1 : m1 -> m2
%2 = mpmd.fragment<"m2"> (%t) ...
```

This allows us to control the creation of cross-mesh transfers, since these are
often the cause of performance regressions. We allow users to control whether to
infer the creation of cross-mesh transfers in the “mesh inference” pass. (Tip: A
good way to get started is often to allow inference of transfers for initial
integration, and then optimize these transfers later.)

### Mesh inference

<ins>Summary</ins>: Completes the mesh assignment of a partially assigned
program, possibly introducing new cross-mesh transfers.

This completes the mesh assignments as follows:

```
// We define the following functions
use_set(op) = union of all meshes that op is transitively used in.
This tells us where the op must live.
src_set(op) = intersection of all meshes that the op has as a
transitive source. This tells us where the op
can live without introducing additional
transfers.

// We assign each op to its use_set:
assignment(op) = use_set(op), where we allow an op to be cloned
            into multiple meshes.


// Example
%a = mpmd.unassign %m1_a <- m1
%t = mpmd.transfer %a : m1 -> m2
%b = mpmd.unassign %m2_b <- m2

%x = stablehlo.add %a, %a
%y = mpmd.assign %x -> m1
%z = stablehlo.add %x, %b
%w = mpmd.assign %z -> m2

use_set(op_x) = {m1, m2}
// Because %t exists on m2 and is the same numeric value as %a
src_set(op_x) = {m1, m2}

use_set(op_z) = {m2}
src_set(op_z) = {}
```

If we allow for introduction of transfers, then transfers are created whenever
`use_set(op)` isn’t contained in `src_set(op)`. Otherwise, we return an error.

Intuitively, an op needs to exist in wherever it’s used, which is exactly the
use_set and that’s why the use_set takes a union. And an op can only be computed
on where it exists on, which is why the src_set takes an intersection. It’s
worth noting that the src_set is the dual of the use_set.

### Fragment scheduling

<ins>Summary</ins>: This applies a user-provided schedule to the MPMD program.
E.g. for pipelining, it can apply 1F1B, Near Zero Bubble, etc.

Scheduling decisions are described by referring to user-defined fragments. These
are identified by computation name and transpose count, e.g. the forward layer
has a transpose count of 0 and the backward layer has a transpose count of 1,
etc. The schedule is just a set of dependencies between fragments in the
pipeline.

For example, to generate a 1F1B pipeline, the user could define this schedule:

```
schedule: List[Tuple[Fragment]] = []

for mb_id in range(num_microbatches):
  for stage_id in range(num_stages):
    fwd = mpmd.Fragment(
      name=layer_name,
      transpose_count=0,
      pipeline_stage_id=stage_id,
      microbatch_id=mb_id)
    bwd = mpmd.Fragment(
      name=layer_name,
      transpose_count=1,
      pipeline_stage_id=stage_id,
      microbatch_id=mb_id)

    if stage_id > 0:
      prev_fwd = mpmd.Fragment(
        name=layer_name,
        transpose_count=0,
        pipeline_stage_id=stage_id - 1,
        microbatch_id=mb_id)
      schedule.append((prev_fwd, fwd))

    schedule.append((fwd, bwd))

    if stage_id < num_stages - 1:
      next_bwd = mpmd.Fragment(
        name=layer_name,
        transpose_count=1,
        pipeline_stage_id=stage_id + 1,
        microbatch_id=mb_id)
      schedule.append((next_bwd, bwd))


{ "m0": [Fragment(name=layer0, transpose_count=0, stage_id=0, microbatch_id=0),
         Fragment(name=layer0, transpose_count=0, stage_id=0, microbatch_id=1),
         Fragment(name=layer0, transpose_count=0, stage_id=0, microbatch_id=2),
         Fragment(name=layer0, transpose_count=1, stage_id=0, microbatch_id=0),
         Fragment(name=layer0, transpose_count=1, stage_id=0, microbatch_id=1),
         Fragment(name=layer0, transpose_count=1, stage_id=0, microbatch_id=2)],
  "m1": [
         Fragment(name=layer1, transpose_count=0, stage_id=1, microbatch_id=0),
         Fragment(name=layer1, transpose_count=0, stage_id=1, microbatch_id=1),
         Fragment(name=layer1, transpose_count=1, stage_id=1, microbatch_id=0),
         Fragment(name=layer1, transpose_count=1, stage_id=1, microbatch_id=1),
         Fragment(name=layer1, transpose_count=0, stage_id=1, microbatch_id=2),
         Fragment(name=layer1, transpose_count=1, stage_id=1, microbatch_id=2)]
  "m2": [
         Fragment(name=layer2, transpose_count=0, stage_id=2, microbatch_id=0),
         Fragment(name=layer2, transpose_count=1, stage_id=2, microbatch_id=0),
         Fragment(name=layer2, transpose_count=0, stage_id=2, microbatch_id=1),
         Fragment(name=layer2, transpose_count=1, stage_id=2, microbatch_id=1),
         Fragment(name=layer2, transpose_count=0, stage_id=2, microbatch_id=2),
         Fragment(name=layer2, transpose_count=1, stage_id=2, microbatch_id=2)]}
```

The scheduling compiler pass simply adds dependencies according to the schedule,
and then applies a topological sort.

### Fragment merging

<ins>Summary</ins>: This applies user-provided fragment merging rules to the
MPMD program.

The user provides a set of fragment merging rules. Each rule describes a pair of
fragments to be merged using fragment metadata (same as that used to describe
fragment scheduling).

For example, after scheduling the user may want to merge the forward and
backward fragment of the last pipeline stage in 1F1B. This can be done by
defining a rule like this:

```
fwd_fragment = mpmd.Fragment(
  name=layer_name,
  transpose_count=0,
  pipeline_stage_id=num_stages - 1)
bwd_fragment = mpmd.Fragment(
  name=layer_name,
  transpose_count=1,
  pipeline_stage_id=num_stages - 1)

fragment_merge_rules: List[Tuple[Fragment]] = [(fwd_fragment, bwd_fragment)]
```

The fragment merging compiler pass walks the MLIR module and merges fragments as
required.

### SPMD sharding propagation

<ins>Summary</ins>: Applies fixed-point SPMD sharding propagation to the entire
MPMD program using Shardy.

For example, if the user uses batch + megatron parallelism where fragment 1 has
a tensor with batch sharding and the weight in the second fragment is megatron
sharded (shown in the diagram below), after propagation, the batch sharding gets
propagated from fragment 1 to fragment 2 while megatron sharding still persists.

![Figure3](images/2025-06-17-mpmd-rfc/sharding_propagation.jpg)

MPMD ops (`FragmentOp` and `TransferOp`) in an MPMD program are opaque to Shardy
during propagation. **From Shardy’s perspective, with homogeneous meshes, a MPMD
program is no different from a SPMD program**.

This is done by making MPMD ops implement shardy’s `OpInterfaces`, which defines
how these types of ops should be sharded:

*   `FragmentOp` implements shardy's `ShardableDataFlowOpInterface`. This allows
    shardy to propagate sharding through `FragmentOp`’s operand to block
    arguments and return value to result.
*   `TransferOp` implements shardy’s `ShardingRuleOpInterface` which defines the
    operand the result of a `TransferOp` should be sharded in the same way.

Propagating across heterogenous meshes is a small extension to this: we simply
propagate using the Shardy axes names.

### Export

<ins>Summary</ins>: A mix of passes which prepares the MLIR module for
compilation (XLA or otherwise).

For example,

*   Dedupes similar programs together, to minimize the number of programs which
    need to be compiled.
*   Marks donation aliasing of intermediate programs.
*   Marks the amount of memory reserved by other intermediate values not used by
    the fragment.

### A short note on heterogeneous meshes

Note that aside from sharding propagation above, none of the components rely on
the mesh size. They only rely on the fact that there are in fact different
meshes. Thus, sharding propagation is the main point of interest when dealing
with heterogeneous device types or device groups, but for that we have a
sufficiently simple and expressive heuristic.
